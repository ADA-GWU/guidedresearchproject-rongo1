{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import ConcatDataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "data_dir = 'data/vegetable_images' \n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = ImageFolder(root=data_dir + '/train', transform=transform)\n",
    "val_dataset = ImageFolder(root=data_dir + '/validation', transform=transform)\n",
    "test_dataset = ImageFolder(root=data_dir + '/gaussian_noise/test/100', transform=transform)\n",
    "test_dataset_without_noise = ImageFolder(root=data_dir + '/test', transform=transform)\n",
    "\n",
    "\n",
    "dataloaders = {'train':  DataLoader(train_dataset, batch_size=64, shuffle=True), \n",
    "               'val': DataLoader(val_dataset, batch_size=64)\n",
    "               }\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "test_loader_without_noise = DataLoader(test_dataset_without_noise, batch_size=64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "3000\n",
      "3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bean',\n",
       " 'Bitter_Gourd',\n",
       " 'Bottle_Gourd',\n",
       " 'Brinjal',\n",
       " 'Broccoli',\n",
       " 'Cabbage',\n",
       " 'Capsicum',\n",
       " 'Carrot',\n",
       " 'Cauliflower',\n",
       " 'Cucumber',\n",
       " 'Papaya',\n",
       " 'Potato',\n",
       " 'Pumpkin',\n",
       " 'Radish',\n",
       " 'Tomato']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataloaders['train'].dataset))\n",
    "print(len(dataloaders['val'].dataset))\n",
    "\n",
    "dataset_sizes = {'train' : len(dataloaders['train'].dataset), 'val': len(dataloaders['val'].dataset), 'test': len(test_loader.dataset)}\n",
    "print(len(test_loader.dataset))\n",
    "classes  = train_dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /home/sign-lang/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013715267181396484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 244408911,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb666b9a0bf43ada6accd368e1e4692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model._modules['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=4096, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_features = model._modules['classifier'][-1].in_features\n",
    "out_features = len(classes)\n",
    "model._modules['classifier'][-1] = nn.Linear(in_features, out_features, bias=True)\n",
    "print(model._modules['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN IMAGES WITHOUT NOISE BEFORE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 94.76666666666667 %\n",
      "Accuracy of Bean: 96.0 %\n",
      "Accuracy of Bitter_Gourd: 95.0 %\n",
      "Accuracy of Bottle_Gourd: 94.0 %\n",
      "Accuracy of Brinjal: 94.0 %\n",
      "Accuracy of Broccoli: 91.0 %\n",
      "Accuracy of Cabbage: 97.0 %\n",
      "Accuracy of Capsicum: 93.5 %\n",
      "Accuracy of Carrot: 96.0 %\n",
      "Accuracy of Cauliflower: 97.0 %\n",
      "Accuracy of Cucumber: 90.5 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader_without_noise:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH 100% NOISE BEFORE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 18.0 %\n",
      "Accuracy of Bean: 1.0 %\n",
      "Accuracy of Bitter_Gourd: 91.0 %\n",
      "Accuracy of Bottle_Gourd: 37.5 %\n",
      "Accuracy of Brinjal: 0.0 %\n",
      "Accuracy of Broccoli: 34.5 %\n",
      "Accuracy of Cabbage: 0.0 %\n",
      "Accuracy of Capsicum: 0.0 %\n",
      "Accuracy of Carrot: 2.0 %\n",
      "Accuracy of Cauliflower: 0.5 %\n",
      "Accuracy of Cucumber: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "       \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs =  torch.tensor(inputs).to(device)\n",
    "                labels = torch.tensor(labels).to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "    \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_184765/2272575281.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs =  torch.tensor(inputs).to(device)\n",
      "/tmp/ipykernel_184765/2272575281.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0328 Acc: 0.9917\n",
      "val Loss: 0.0193 Acc: 0.9953\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.0291 Acc: 0.9919\n",
      "val Loss: 0.0168 Acc: 0.9960\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.9950\n",
      "val Loss: 0.0153 Acc: 0.9967\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0197 Acc: 0.9955\n",
      "val Loss: 0.0142 Acc: 0.9963\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0167 Acc: 0.9959\n",
      "val Loss: 0.0135 Acc: 0.9970\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0161 Acc: 0.9958\n",
      "val Loss: 0.0136 Acc: 0.9970\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0135 Acc: 0.9974\n",
      "val Loss: 0.0129 Acc: 0.9963\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0122 Acc: 0.9968\n",
      "val Loss: 0.0125 Acc: 0.9963\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0113 Acc: 0.9973\n",
      "val Loss: 0.0122 Acc: 0.9967\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0102 Acc: 0.9983\n",
      "val Loss: 0.0122 Acc: 0.9967\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0102 Acc: 0.9975\n",
      "val Loss: 0.0121 Acc: 0.9967\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0105 Acc: 0.9974\n",
      "val Loss: 0.0120 Acc: 0.9967\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0109 Acc: 0.9976\n",
      "val Loss: 0.0119 Acc: 0.9967\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0118 Acc: 0.9969\n",
      "val Loss: 0.0120 Acc: 0.9967\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0112 Acc: 0.9973\n",
      "val Loss: 0.0119 Acc: 0.9967\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0104 Acc: 0.9977\n",
      "val Loss: 0.0119 Acc: 0.9967\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0101 Acc: 0.9977\n",
      "val Loss: 0.0119 Acc: 0.9967\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0098 Acc: 0.9982\n",
      "val Loss: 0.0118 Acc: 0.9967\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0102 Acc: 0.9981\n",
      "val Loss: 0.0118 Acc: 0.9967\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0099 Acc: 0.9981\n",
      "val Loss: 0.0118 Acc: 0.9967\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0106 Acc: 0.9977\n",
      "val Loss: 0.0118 Acc: 0.9967\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0124 Acc: 0.9968\n",
      "val Loss: 0.0118 Acc: 0.9967\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0100 Acc: 0.9979\n",
      "val Loss: 0.0118 Acc: 0.9967\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0104 Acc: 0.9979\n",
      "val Loss: 0.0118 Acc: 0.9967\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0103 Acc: 0.9978\n",
      "val Loss: 0.0118 Acc: 0.9967\n",
      "\n",
      "Training complete in 16m 40s\n",
      "Best val Acc: 0.997000\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 99.66666666666667 %\n",
      "Accuracy of Bean: 100.0 %\n",
      "Accuracy of Bitter_Gourd: 99.0 %\n",
      "Accuracy of Bottle_Gourd: 100.0 %\n",
      "Accuracy of Brinjal: 99.5 %\n",
      "Accuracy of Broccoli: 99.0 %\n",
      "Accuracy of Cabbage: 99.5 %\n",
      "Accuracy of Capsicum: 99.5 %\n",
      "Accuracy of Carrot: 100.0 %\n",
      "Accuracy of Cauliflower: 100.0 %\n",
      "Accuracy of Cucumber: 99.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader_without_noise:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 15.533333333333333 %\n",
      "Accuracy of Bean: 0.0 %\n",
      "Accuracy of Bitter_Gourd: 95.0 %\n",
      "Accuracy of Bottle_Gourd: 9.5 %\n",
      "Accuracy of Brinjal: 0.0 %\n",
      "Accuracy of Broccoli: 27.5 %\n",
      "Accuracy of Cabbage: 0.0 %\n",
      "Accuracy of Capsicum: 0.0 %\n",
      "Accuracy of Carrot: 0.5 %\n",
      "Accuracy of Cauliflower: 0.5 %\n",
      "Accuracy of Cucumber: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign-lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
