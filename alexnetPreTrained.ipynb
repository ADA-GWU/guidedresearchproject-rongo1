{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import ConcatDataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "data_dir = 'data/vegetable_images' \n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = ImageFolder(root=data_dir + '/train', transform=transform)\n",
    "val_dataset = ImageFolder(root=data_dir + '/validation', transform=transform)\n",
    "\n",
    "val_dataset_with_noise = ImageFolder(root=data_dir + '/gaussian_noise/validation/100', transform=transform)\n",
    "test_dataset = ImageFolder(root=data_dir + '/gaussian_noise/test/100', transform=transform)\n",
    "test_dataset_without_noise = ImageFolder(root=data_dir + '/test', transform=transform)\n",
    "\n",
    "\n",
    "dataloaders = {'train':  DataLoader(train_dataset, batch_size=64, shuffle=True), \n",
    "               'val': DataLoader(val_dataset, batch_size=64)\n",
    "               }\n",
    "\n",
    "dataloaders_with_noise = {'train':  DataLoader(train_dataset, batch_size=64, shuffle=True), \n",
    "               'val': DataLoader(val_dataset_with_noise, batch_size=64)\n",
    "               }\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "test_loader_without_noise = DataLoader(test_dataset_without_noise, batch_size=64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "3000\n",
      "3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bean',\n",
       " 'Bitter_Gourd',\n",
       " 'Bottle_Gourd',\n",
       " 'Brinjal',\n",
       " 'Broccoli',\n",
       " 'Cabbage',\n",
       " 'Capsicum',\n",
       " 'Carrot',\n",
       " 'Cauliflower',\n",
       " 'Cucumber',\n",
       " 'Papaya',\n",
       " 'Potato',\n",
       " 'Pumpkin',\n",
       " 'Radish',\n",
       " 'Tomato']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataloaders['train'].dataset))\n",
    "print(len(dataloaders['val'].dataset))\n",
    "\n",
    "dataset_sizes = {'train' : len(dataloaders['train'].dataset), 'val': len(dataloaders['val'].dataset), 'test': len(test_loader.dataset)}\n",
    "print(len(test_loader.dataset))\n",
    "classes  = train_dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model._modules['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=4096, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_features = model._modules['classifier'][-1].in_features\n",
    "out_features = len(classes)\n",
    "model._modules['classifier'][-1] = nn.Linear(in_features, out_features, bias=True)\n",
    "print(model._modules['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN IMAGES WITHOUT NOISE BEFORE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 7.6 %\n",
      "Accuracy of Bean: 15.0 %\n",
      "Accuracy of Bitter_Gourd: 1.0 %\n",
      "Accuracy of Bottle_Gourd: 1.0 %\n",
      "Accuracy of Brinjal: 4.0 %\n",
      "Accuracy of Broccoli: 1.0 %\n",
      "Accuracy of Cabbage: 15.5 %\n",
      "Accuracy of Capsicum: 0.0 %\n",
      "Accuracy of Carrot: 1.5 %\n",
      "Accuracy of Cauliflower: 1.5 %\n",
      "Accuracy of Cucumber: 7.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader_without_noise:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH 100% NOISE BEFORE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 7.533333333333333 %\n",
      "Accuracy of Bean: 44.5 %\n",
      "Accuracy of Bitter_Gourd: 0.5 %\n",
      "Accuracy of Bottle_Gourd: 1.5 %\n",
      "Accuracy of Brinjal: 0.0 %\n",
      "Accuracy of Broccoli: 13.0 %\n",
      "Accuracy of Cabbage: 17.5 %\n",
      "Accuracy of Capsicum: 4.5 %\n",
      "Accuracy of Carrot: 3.0 %\n",
      "Accuracy of Cauliflower: 14.5 %\n",
      "Accuracy of Cucumber: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "       \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs =  torch.tensor(inputs).to(device)\n",
    "                labels = torch.tensor(labels).to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "    \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_189093/2272575281.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs =  torch.tensor(inputs).to(device)\n",
      "/tmp/ipykernel_189093/2272575281.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5360 Acc: 0.8581\n",
      "val Loss: 0.0945 Acc: 0.9740\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.1065 Acc: 0.9697\n",
      "val Loss: 0.0501 Acc: 0.9890\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0653 Acc: 0.9817\n",
      "val Loss: 0.0299 Acc: 0.9947\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0453 Acc: 0.9874\n",
      "val Loss: 0.0240 Acc: 0.9943\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0349 Acc: 0.9906\n",
      "val Loss: 0.0196 Acc: 0.9943\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0291 Acc: 0.9927\n",
      "val Loss: 0.0173 Acc: 0.9950\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0243 Acc: 0.9932\n",
      "val Loss: 0.0178 Acc: 0.9953\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0210 Acc: 0.9947\n",
      "val Loss: 0.0159 Acc: 0.9957\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0184 Acc: 0.9957\n",
      "val Loss: 0.0159 Acc: 0.9953\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0198 Acc: 0.9955\n",
      "val Loss: 0.0156 Acc: 0.9957\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0191 Acc: 0.9953\n",
      "val Loss: 0.0152 Acc: 0.9957\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0182 Acc: 0.9957\n",
      "val Loss: 0.0150 Acc: 0.9957\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0192 Acc: 0.9952\n",
      "val Loss: 0.0148 Acc: 0.9957\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0174 Acc: 0.9959\n",
      "val Loss: 0.0149 Acc: 0.9953\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0173 Acc: 0.9958\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 99.66666666666667 %\n",
      "Accuracy of Bean: 100.0 %\n",
      "Accuracy of Bitter_Gourd: 99.0 %\n",
      "Accuracy of Bottle_Gourd: 100.0 %\n",
      "Accuracy of Brinjal: 99.5 %\n",
      "Accuracy of Broccoli: 99.0 %\n",
      "Accuracy of Cabbage: 99.5 %\n",
      "Accuracy of Capsicum: 99.5 %\n",
      "Accuracy of Carrot: 100.0 %\n",
      "Accuracy of Cauliflower: 100.0 %\n",
      "Accuracy of Cucumber: 99.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader_without_noise:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 15.533333333333333 %\n",
      "Accuracy of Bean: 0.0 %\n",
      "Accuracy of Bitter_Gourd: 95.0 %\n",
      "Accuracy of Bottle_Gourd: 9.5 %\n",
      "Accuracy of Brinjal: 0.0 %\n",
      "Accuracy of Broccoli: 27.5 %\n",
      "Accuracy of Cabbage: 0.0 %\n",
      "Accuracy of Capsicum: 0.0 %\n",
      "Accuracy of Carrot: 0.5 %\n",
      "Accuracy of Cauliflower: 0.5 %\n",
      "Accuracy of Cucumber: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign-lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
