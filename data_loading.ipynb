{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import ConcatDataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_indexes(arr, value):\n",
    "    indexes = []\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] == value:\n",
    "            indexes.append(i)\n",
    "    return indexes\n",
    "\n",
    "def get_length_per_class(dataloader, classes):\n",
    "    class_counts = defaultdict(int)\n",
    "    total = 0\n",
    "    for batch in dataloader:\n",
    "        _, labels = batch \n",
    "        labels = labels.numpy().tolist()\n",
    "        for label in labels:\n",
    "            class_counts[label] += 1\n",
    "            total +=1\n",
    "\n",
    "    class_counts = dict(sorted(class_counts.items()))\n",
    "    for class_label, count in class_counts.items():\n",
    "        print(f\"Class {classes[class_label]}: {count} samples out of {total}\")\n",
    "def load_data(data_dir,\n",
    "                           batch_size,\n",
    "                           data_type,\n",
    "                           noise_type,\n",
    "                           noise_percentage,                           \n",
    "                           transform,                           \n",
    "                           data_percentage=1):\n",
    "    \n",
    "    if noise_type == \"None\":\n",
    "        noise_type = \"\"\n",
    "        noise_percentage = \"\"\n",
    "    else:\n",
    "        noise_percentage = \"/\" + str(noise_percentage)\n",
    "    path = data_dir + \"/\" + noise_type + \"/\" + data_type + noise_percentage\n",
    "    print(\"path: \", path)\n",
    "    dataset = ImageFolder(root=path, transform=transform)\n",
    "    original_classes = dataset.classes \n",
    "    num_samples = len(dataset)\n",
    "    indices = list(range(num_samples))\n",
    "\n",
    "    labels = dataset.targets\n",
    "    class_to_idx = dataset.class_to_idx\n",
    "    \n",
    "\n",
    "    needed_length = int(num_samples*data_percentage/100)\n",
    "    expected_length_per_class = int(needed_length/len(original_classes))\n",
    "    print(f\"needed_length: {needed_length}, expected_length_per_class: {expected_length_per_class}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    if data_percentage != 100:\n",
    "        new_indices = []\n",
    "        for key, value in class_to_idx.items():\n",
    "            all_indixes_of_class = get_indexes(labels, value)\n",
    "            new_indices.extend(all_indixes_of_class[:expected_length_per_class])\n",
    "    else:\n",
    "        new_indices = indices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    length_dataset = len(new_indices)\n",
    "    print(\"length of final dataset:\", length_dataset)\n",
    "    sampler = SubsetRandomSampler(new_indices)\n",
    "\n",
    "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "    return dataloader, length_dataset, original_classes\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:  ../data/vegetable_images/gaussian_noise/test/100\n",
      "needed_length: 3000, expected_length_per_class: 200\n",
      "length of final dataset: 3000\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "data_dir = '../data/vegetable_images' \n",
    "batch_size = 64\n",
    "data_type = \"test\"\n",
    "noise_type = \"gaussian_noise\"\n",
    "noise_percentage = 100                    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])                   \n",
    "data_percentage = 100\n",
    "\n",
    "\n",
    "\n",
    "a, b ,c = load_data(data_dir,\n",
    "                           batch_size,\n",
    "                           data_type,\n",
    "                           noise_type,\n",
    "                           noise_percentage,                           \n",
    "                           transform,                           \n",
    "                           data_percentage=data_percentage)\n",
    "\n",
    "# print(dataloader, l, c )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 3, 227, 227])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(a))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Bean: 200 samples out of 3000\n",
      "Class Bitter_Gourd: 200 samples out of 3000\n",
      "Class Bottle_Gourd: 200 samples out of 3000\n",
      "Class Brinjal: 200 samples out of 3000\n",
      "Class Broccoli: 200 samples out of 3000\n",
      "Class Cabbage: 200 samples out of 3000\n",
      "Class Capsicum: 200 samples out of 3000\n",
      "Class Carrot: 200 samples out of 3000\n",
      "Class Cauliflower: 200 samples out of 3000\n",
      "Class Cucumber: 200 samples out of 3000\n",
      "Class Papaya: 200 samples out of 3000\n",
      "Class Potato: 200 samples out of 3000\n",
      "Class Pumpkin: 200 samples out of 3000\n",
      "Class Radish: 200 samples out of 3000\n",
      "Class Tomato: 200 samples out of 3000\n"
     ]
    }
   ],
   "source": [
    "get_length_per_class(a, c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
