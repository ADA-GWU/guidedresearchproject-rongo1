{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import ConcatDataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir,\n",
    "                           batch_size,\n",
    "                           data_type,\n",
    "                           noise_type,\n",
    "                           noise_percentage,                           \n",
    "                           transform,                           \n",
    "                           data_percentage=0.1,\n",
    "                           random_seed = 1,\n",
    "                           shuffle=True):\n",
    "    \n",
    "\n",
    "    noise_type = \"\" if noise_type == \"None\" else noise_type\n",
    "    path = data_dir + \"/\" + noise_type  + \"/\" + data_type\n",
    "    print(\"path: \", path)\n",
    "    dataset = ImageFolder(root=path, transform=transform)\n",
    "  \n",
    "\n",
    "    num_samples = len(dataset)\n",
    "    print(\"length of original dataset:\", num_samples)\n",
    "    indices = list(range(num_samples)) \n",
    "    if data_percentage != 1:\n",
    "        needed_length = int(num_samples*data_percentage)\n",
    "        random.shuffle(indices)\n",
    "        indices = indices[:needed_length]\n",
    "    print(len(indices))\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:  ../data/vegetable_images/gaussian_noise/test\n",
      "length of original dataset: 15000\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data/vegetable_images' \n",
    "batch_size = 64\n",
    "data_type = \"test\"\n",
    "noise_type = \"gaussian_noise\"\n",
    "noise_percentage = 100                    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])                   \n",
    "data_percentage = 0.1\n",
    "\n",
    "\n",
    "load_data(data_dir,\n",
    "                           batch_size,\n",
    "                           data_type,\n",
    "                           noise_type,\n",
    "                           noise_percentage,                           \n",
    "                           transform,                           \n",
    "                           data_percentage=data_percentage,\n",
    "                           random_seed = 1,\n",
    "                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
